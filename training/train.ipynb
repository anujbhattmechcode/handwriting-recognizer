{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dataset_creator import DatasetCreator\n",
    "from data_preparation import DataPreperation\n",
    "from tensorflow.keras.layers import StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prep = DataPreperation(\"../data\")\n",
    "ds_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "char_to_num = StringLookup(vocabulary=list(ds_prep.characters), mask_token=None)\n",
    "\n",
    "num_to_char = StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "padding_token = 99\n",
    "image_width = 128\n",
    "image_height = 32\n",
    "\n",
    "\n",
    "ds_creator = DatasetCreator(\n",
    "    ds_prep.train_img_paths,\n",
    "    ds_prep.train_labels_cleaned,\n",
    "    ds_prep.max_len,\n",
    "    char_to_num,\n",
    "    num_to_char,\n",
    "    AUTOTUNE,\n",
    "    batch_size,\n",
    "    padding_token,\n",
    "    image_width,\n",
    "    image_height\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds_creator.prepare_dataset(ds_prep.train_img_paths, ds_prep.train_labels_cleaned)\n",
    "validation_ds = ds_creator.prepare_dataset(ds_prep.validation_img_paths, ds_prep.validation_labels_cleaned)\n",
    "test_ds = ds_creator.prepare_dataset(ds_prep.test_img_paths, ds_prep.test_labels_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    _, ax = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "    for i in range(4):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, 99)))\n",
    "        \n",
    "        label = tf.strings.reduce_join(num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 2, i % 2].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 2, i % 2].set_title(label)\n",
    "        ax[i // 2, i % 2].axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = []\n",
    "validation_labels = []\n",
    "\n",
    "for batch in validation_ds:\n",
    "    validation_images.append(batch[\"image\"])    \n",
    "    validation_labels.append(batch[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(labels, predictions):\n",
    "    saprse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)\n",
    "\n",
    "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "    predictions_decoded = tf.keras.backend.ctc_decode(\n",
    "        predictions, input_length=input_len, greedy=True\n",
    "    )[0][0][:, :ds_prep.max_len]\n",
    "    sparse_predictions = tf.cast(\n",
    "        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64\n",
    "    )\n",
    "\n",
    "    edit_distances = tf.edit_distance(\n",
    "        sparse_predictions, saprse_labels, normalize=False\n",
    "    )\n",
    "    return tf.reduce_mean(edit_distances)\n",
    "\n",
    "\n",
    "class EditDistanceCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, pred_model):\n",
    "        super().__init__()\n",
    "        self.prediction_model = pred_model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        edit_distances = []\n",
    "\n",
    "        for i in range(len(validation_images)):\n",
    "            labels = validation_labels[i]\n",
    "            predictions = self.prediction_model.predict(validation_images[i])\n",
    "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "\n",
    "        print(\n",
    "            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_architacture import build_model\n",
    "\n",
    "model = build_model(image_width, image_height, char_to_num)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # 50\n",
    "\n",
    "model = build_model(image_width, image_height, char_to_num)\n",
    "prediction_model = tf.keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[edit_distance_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss Values\")\n",
    "ax.plot(history.history['loss'], lw=2.5, c='gray', label='Train Cost function output')\n",
    "ax.plot(history.history['val_loss'], lw=2.5, c='black', label='Validation Cost function output')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"handwriting_recognizer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image (InputLayer)          [(None, 128, 32, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 128, 32, 32)          320       ['image[0][0]']               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)        (None, 64, 16, 32)           0         ['Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)              (None, 64, 16, 64)           18496     ['pool1[0][0]']               \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)        (None, 32, 8, 64)            0         ['Conv2[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 32, 512)              0         ['pool2[0][0]']               \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 32, 64)               32832     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 32, 64)               0         ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 32, 256)              197632    ['dropout_1[0][0]']           \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, 32, 128)              164352    ['bidirectional_2[0][0]']     \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " label (InputLayer)          [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 32, 81)               10449     ['bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)         (None, 32, 81)               0         ['label[0][0]',               \n",
      "                                                                     'dense2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 424081 (1.62 MB)\n",
      "Trainable params: 424081 (1.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :ds_prep.max_len\n",
    "    ]\n",
    "    \n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text\n",
    "\n",
    "for batch in test_ds.take(1):\n",
    "    batch_images = batch[\"image\"]\n",
    "    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n",
    "\n",
    "    preds = prediction_model.predict(batch_images)\n",
    "    pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "    for i in range(16):\n",
    "        img = batch_images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        title = f\"Prediction: {pred_texts[i]}\"\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(title)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kepler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
